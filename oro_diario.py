"""
An√°lisis de Fat Tails en los Precios del Oro Con Precios Diarios
Este programa analiza qu√© tan "fat tails" (colas gruesas) tiene la distribuci√≥n
de los retornos logar√≠tmicos del oro compar√°ndola con una distribuci√≥n normal.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import seaborn as sns
import os
from datetime import datetime

# Configuraci√≥n de estilo
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

def cargar_datos(archivo):
    """
    Carga los datos del archivo (CSV o Excel)
    """
    try:
        # Intentar leer el archivo
        print(f"\nüìÇ Intentando cargar: {archivo}")
        
        # Detectar el tipo de archivo por extensi√≥n
        if archivo.lower().endswith('.csv'):
            df = pd.read_csv(archivo)
            print(f"‚úì Archivo CSV cargado")
        elif archivo.lower().endswith(('.xlsx', '.xls')):
            # Primero, obtener informaci√≥n sobre las hojas disponibles
            excel_file = pd.ExcelFile(archivo)
            print(f"‚úì Archivo Excel encontrado")
            print(f"‚úì Hojas disponibles: {excel_file.sheet_names}")
            
            # Leer la primera hoja (o especificar cual usar)
            if len(excel_file.sheet_names) > 1:
                print(f"\n‚ö†Ô∏è  El archivo tiene m√∫ltiples hojas. Usando la primera: '{excel_file.sheet_names[0]}'")
            
            df = pd.read_excel(archivo, sheet_name=0)
        else:
            print(f"\n‚ùå Error: Formato de archivo no soportado. Use .csv, .xlsx o .xls")
            return None
        
        print(f"‚úì Datos cargados exitosamente: {len(df)} filas")
        print(f"‚úì Columnas disponibles: {list(df.columns)}")
        
        # Mostrar primeras filas para diagn√≥stico
        if len(df) > 0:
            print(f"\nüìã Primeras 3 filas del archivo:")
            print(df.head(3))
        else:
            print("\n‚ö†Ô∏è  ADVERTENCIA: El archivo no contiene datos (0 filas)")
        
        return df
    except FileNotFoundError:
        print(f"\n‚ùå Error: No se encuentra el archivo '{archivo}'")
        print("Aseg√∫rate de que el archivo existe y la ruta es correcta")
        return None
    except Exception as e:
        print(f"\n‚ùå Error al cargar el archivo: {e}")
        print(f"Tipo de error: {type(e).__name__}")
        return None

def analizar_fat_tails(retornos):
    """
    Analiza las caracter√≠sticas de fat tails de los retornos
    """
    # Eliminar valores NaN
    retornos_limpios = retornos.dropna()
    
    # Estad√≠sticas b√°sicas
    media = retornos_limpios.mean()
    desviacion = retornos_limpios.std()
    
    # Kurtosis - Medida clave de fat tails
    # Kurtosis > 3 indica fat tails (m√°s que una distribuci√≥n normal)
    kurtosis_exceso = stats.kurtosis(retornos_limpios, fisher=True)  # Exceso sobre 3
    kurtosis_total = stats.kurtosis(retornos_limpios, fisher=False)  # Total
    
    # Skewness - Asimetr√≠a
    asimetria = stats.skew(retornos_limpios)
    
    # Test de normalidad Jarque-Bera
    jb_stat, jb_pvalue = stats.jarque_bera(retornos_limpios)
    
    # Test de normalidad Shapiro-Wilk (m√°s potente para muestras peque√±as)
    if len(retornos_limpios) <= 5000:
        sw_stat, sw_pvalue = stats.shapiro(retornos_limpios)
    else:
        sw_stat, sw_pvalue = None, None
    
    # Calcular percentiles extremos
    percentil_1 = np.percentile(retornos_limpios, 1)
    percentil_99 = np.percentile(retornos_limpios, 99)
    percentil_5 = np.percentile(retornos_limpios, 5)
    percentil_95 = np.percentile(retornos_limpios, 95)
    
    # Contar observaciones extremas (m√°s all√° de 3 desviaciones est√°ndar)
    limite_superior = media + 3 * desviacion
    limite_inferior = media - 3 * desviacion
    extremos = np.sum((retornos_limpios > limite_superior) | (retornos_limpios < limite_inferior))
    porcentaje_extremos = (extremos / len(retornos_limpios)) * 100
    
    # En una distribuci√≥n normal, esperamos ~0.27% m√°s all√° de 3 sigma
    extremos_esperados_normal = len(retornos_limpios) * 0.0027
    
    resultados = {
        'n_observaciones': len(retornos_limpios),
        'media': media,
        'desviacion': desviacion,
        'kurtosis_exceso': kurtosis_exceso,
        'kurtosis_total': kurtosis_total,
        'asimetria': asimetria,
        'jb_statistic': jb_stat,
        'jb_pvalue': jb_pvalue,
        'sw_statistic': sw_stat,
        'sw_pvalue': sw_pvalue,
        'percentil_1': percentil_1,
        'percentil_99': percentil_99,
        'percentil_5': percentil_5,
        'percentil_95': percentil_95,
        'extremos_observados': extremos,
        'porcentaje_extremos': porcentaje_extremos,
        'extremos_esperados_normal': extremos_esperados_normal
    }
    
    return resultados, retornos_limpios

def calcular_hill_estimator(datos, k=None):
    """
    Calcula el estimador de Hill para el exponente de cola.
    
    Par√°metros:
    - datos: array de valores (debe ser para una cola, valores extremos)
    - k: n√∫mero de observaciones extremas a usar (si None, usa regla emp√≠rica)
    
    Retorna:
    - alpha: exponente de cola (√≠ndice de cola)
    - k_usado: n√∫mero de observaciones usadas
    
    Interpretaci√≥n:
    - Œ± < 2: Varianza infinita (colas muy gruesas, distribuci√≥n no tiene varianza)
    - Œ± < 3: Colas m√°s gruesas que la normal
    - Œ± < 4: Kurtosis infinita
    - Œ± m√°s peque√±o = colas m√°s gruesas
    """
    n = len(datos)
    
    # Ordenar datos de mayor a menor (para cola superior)
    datos_ordenados = np.sort(datos)[::-1]
    
    # Si no se especifica k, usar regla emp√≠rica: k ‚âà sqrt(n) o n^0.5
    if k is None:
        k = max(int(np.sqrt(n)), 10)  # M√≠nimo 10 observaciones
        k = min(k, n // 2)  # M√°ximo la mitad de los datos
    
    # Asegurar que k es v√°lido
    k = max(1, min(k, n - 1))
    
    # Estimador de Hill
    # Œ±_hat = [1/k * Œ£(log(X_i) - log(X_(k+1)))]^(-1)
    X_k_plus_1 = datos_ordenados[k]
    
    if X_k_plus_1 <= 0:
        return np.nan, k
    
    suma_logs = np.sum(np.log(datos_ordenados[:k]) - np.log(X_k_plus_1))
    alpha = k / suma_logs if suma_logs > 0 else np.nan
    
    return alpha, k

def analizar_exponentes_cola(retornos_limpios):
    """
    Analiza los exponentes de cola usando el estimador de Hill
    para las colas superior e inferior.
    """
    print("\n" + "="*70)
    print("AN√ÅLISIS DE EXPONENTES DE COLA (ESTIMADOR DE HILL)")
    print("="*70)
    
    # Separar retornos positivos (cola superior) y negativos (cola inferior)
    retornos_positivos = retornos_limpios[retornos_limpios > 0].values
    retornos_negativos = np.abs(retornos_limpios[retornos_limpios < 0].values)
    
    # Calcular diferentes valores de k para ver la estabilidad
    n_pos = len(retornos_positivos)
    n_neg = len(retornos_negativos)
    
    # Usar varios valores de k para verificar robustez
    k_values = [
        int(np.sqrt(n_pos)),
        int(n_pos * 0.05),  # 5% superior
        int(n_pos * 0.10),  # 10% superior
    ]
    
    print(f"\nüìä COLA SUPERIOR (retornos positivos):")
    print(f"   Total de observaciones: {n_pos}")
    
    alphas_superior = []
    for k in k_values:
        if k > 0 and k < n_pos:
            alpha, k_usado = calcular_hill_estimator(retornos_positivos, k)
            if not np.isnan(alpha):
                alphas_superior.append(alpha)
                print(f"   k = {k_usado:4d} ({100*k_usado/n_pos:5.1f}%) ‚Üí Œ± = {alpha:.4f}")
    
    if alphas_superior:
        alpha_superior_promedio = np.mean(alphas_superior)
        print(f"\n   ‚úì Exponente promedio (Œ± superior): {alpha_superior_promedio:.4f}")
        
        # Interpretaci√≥n
        if alpha_superior_promedio < 2:
            print(f"   ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è  COLA EXTREMADAMENTE GRUESA (Œ± < 2): Varianza infinita!")
        elif alpha_superior_promedio < 3:
            print(f"   ‚ö†Ô∏è‚ö†Ô∏è  COLA MUY GRUESA (2 ‚â§ Œ± < 3): M√°s gruesa que distribuci√≥n normal")
        elif alpha_superior_promedio < 4:
            print(f"   ‚ö†Ô∏è  COLA GRUESA (3 ‚â§ Œ± < 4): Kurtosis infinita")
        else:
            print(f"   ‚úì Cola moderada (Œ± ‚â• 4)")
    
    print(f"\nüìä COLA INFERIOR (retornos negativos, en valor absoluto):")
    print(f"   Total de observaciones: {n_neg}")
    
    k_values_neg = [
        int(np.sqrt(n_neg)),
        int(n_neg * 0.05),
        int(n_neg * 0.10),
    ]
    
    alphas_inferior = []
    for k in k_values_neg:
        if k > 0 and k < n_neg:
            alpha, k_usado = calcular_hill_estimator(retornos_negativos, k)
            if not np.isnan(alpha):
                alphas_inferior.append(alpha)
                print(f"   k = {k_usado:4d} ({100*k_usado/n_neg:5.1f}%) ‚Üí Œ± = {alpha:.4f}")
    
    if alphas_inferior:
        alpha_inferior_promedio = np.mean(alphas_inferior)
        print(f"\n   ‚úì Exponente promedio (Œ± inferior): {alpha_inferior_promedio:.4f}")
        
        # Interpretaci√≥n
        if alpha_inferior_promedio < 2:
            print(f"   ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è  COLA EXTREMADAMENTE GRUESA (Œ± < 2): Varianza infinita!")
        elif alpha_inferior_promedio < 3:
            print(f"   ‚ö†Ô∏è‚ö†Ô∏è  COLA MUY GRUESA (2 ‚â§ Œ± < 3): M√°s gruesa que distribuci√≥n normal")
        elif alpha_inferior_promedio < 4:
            print(f"   ‚ö†Ô∏è  COLA GRUESA (3 ‚â§ Œ± < 4): Kurtosis infinita")
        else:
            print(f"   ‚úì Cola moderada (Œ± ‚â• 4)")
    
    # Comparaci√≥n
    if alphas_superior and alphas_inferior:
        print(f"\nüìà COMPARACI√ìN DE COLAS:")
        print(f"   Œ± superior: {alpha_superior_promedio:.4f}")
        print(f"   Œ± inferior: {alpha_inferior_promedio:.4f}")
        
        diferencia = abs(alpha_superior_promedio - alpha_inferior_promedio)
        if diferencia < 0.5:
            print(f"   ‚Üí Colas aproximadamente sim√©tricas")
        elif alpha_superior_promedio < alpha_inferior_promedio:
            print(f"   ‚Üí Cola superior m√°s gruesa (m√°s riesgo de subidas extremas)")
        else:
            print(f"   ‚Üí Cola inferior m√°s gruesa (m√°s riesgo de ca√≠das extremas)")
    
    print("\n" + "="*70)
    print("INTERPRETACI√ìN DEL EXPONENTE Œ±:")
    print("  ‚Ä¢ Œ± < 2  : Varianza infinita (muy peligroso)")
    print("  ‚Ä¢ 2‚â§Œ±<3  : Colas m√°s gruesas que la normal")
    print("  ‚Ä¢ 3‚â§Œ±<4  : Kurtosis infinita")
    print("  ‚Ä¢ Œ± ‚â• 4  : Comportamiento m√°s cercano a la normal")
    print("  ‚Ä¢ Menor Œ± = Mayor riesgo de eventos extremos")
    print("="*70)
    
    resultados_hill = {
        'alpha_superior': alpha_superior_promedio if alphas_superior else np.nan,
        'alpha_inferior': alpha_inferior_promedio if alphas_inferior else np.nan,
        'alphas_superior_lista': alphas_superior,
        'alphas_inferior_lista': alphas_inferior
    }
    
    return resultados_hill

def imprimir_resultados(resultados):
    """
    Imprime un reporte detallado de los resultados
    """
    print("\n" + "="*70)
    print("AN√ÅLISIS DE FAT TAILS - RETORNOS DEL ORO (PRECIOS DIARIOS)")
    print("="*70)
    
    print(f"\nüìä ESTAD√çSTICAS DESCRIPTIVAS:")
    print(f"   N√∫mero de observaciones: {resultados['n_observaciones']}")
    print(f"   Media: {resultados['media']:.6f}")
    print(f"   Desviaci√≥n est√°ndar: {resultados['desviacion']:.6f}")
    
    print(f"\nüéØ MEDIDAS DE FAT TAILS:")
    print(f"   Kurtosis (exceso): {resultados['kurtosis_exceso']:.4f}")
    print(f"   Kurtosis (total): {resultados['kurtosis_total']:.4f}")
    print(f"   ‚Üí Distribuci√≥n normal tiene kurtosis = 3.0 (exceso = 0)")
    
    if resultados['kurtosis_exceso'] > 0:
        print(f"   ‚ö†Ô∏è  CONCLUSI√ìN: Fat tails detectadas (kurtosis exceso > 0)")
        if resultados['kurtosis_exceso'] > 3:
            print(f"   ‚ö†Ô∏è‚ö†Ô∏è  Fat tails SEVERAS (kurtosis exceso > 3)")
    else:
        print(f"   ‚úì No hay evidencia de fat tails (kurtosis exceso ‚â§ 0)")
    
    print(f"\nüìê ASIMETR√çA:")
    print(f"   Skewness: {resultados['asimetria']:.4f}")
    if abs(resultados['asimetria']) < 0.5:
        print(f"   ‚Üí Distribuci√≥n aproximadamente sim√©trica")
    elif resultados['asimetria'] > 0:
        print(f"   ‚Üí Distribuci√≥n sesgada a la derecha (cola derecha m√°s larga)")
    else:
        print(f"   ‚Üí Distribuci√≥n sesgada a la izquierda (cola izquierda m√°s larga)")
    
    print(f"\nüß™ TESTS DE NORMALIDAD:")
    print(f"   Jarque-Bera statistic: {resultados['jb_statistic']:.4f}")
    print(f"   Jarque-Bera p-value: {resultados['jb_pvalue']:.6f}")
    if resultados['jb_pvalue'] < 0.05:
        print(f"   ‚úó Se rechaza normalidad (p < 0.05)")
    else:
        print(f"   ‚úì No se rechaza normalidad (p ‚â• 0.05)")
    
    if resultados['sw_pvalue'] is not None:
        print(f"\n   Shapiro-Wilk statistic: {resultados['sw_statistic']:.4f}")
        print(f"   Shapiro-Wilk p-value: {resultados['sw_pvalue']:.6f}")
        if resultados['sw_pvalue'] < 0.05:
            print(f"   ‚úó Se rechaza normalidad (p < 0.05)")
        else:
            print(f"   ‚úì No se rechaza normalidad (p ‚â• 0.05)")
    
    print(f"\nüìç PERCENTILES:")
    print(f"   1%: {resultados['percentil_1']:.6f}")
    print(f"   5%: {resultados['percentil_5']:.6f}")
    print(f"   95%: {resultados['percentil_95']:.6f}")
    print(f"   99%: {resultados['percentil_99']:.6f}")
    
    print(f"\n‚ö° EVENTOS EXTREMOS (m√°s all√° de ¬±3œÉ):")
    print(f"   Observados: {resultados['extremos_observados']} ({resultados['porcentaje_extremos']:.2f}%)")
    print(f"   Esperados (dist. normal): {resultados['extremos_esperados_normal']:.1f} (0.27%)")
    ratio = resultados['extremos_observados'] / max(resultados['extremos_esperados_normal'], 1)
    print(f"   Ratio observados/esperados: {ratio:.2f}x")
    
    if ratio > 2:
        print(f"   ‚ö†Ô∏è  Eventos extremos mucho m√°s frecuentes que en dist. normal")
    
    print("\n" + "="*70)

def crear_visualizaciones(retornos_limpios, resultados):
    """
    Crea visualizaciones para analizar fat tails.
    Guarda cada gr√°fico en un archivo PNG separado dentro de una carpeta con la fecha.
    """
    # Crear carpeta con fecha y hora actual
    fecha_hora = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    carpeta_salida = f"analisis_oro_preciosdiarios{fecha_hora}"
    
    # Crear la carpeta si no existe
    if not os.path.exists(carpeta_salida):
        os.makedirs(carpeta_salida)
        print(f"\nüìÅ Carpeta creada: {carpeta_salida}")
    
    mu, sigma = resultados['media'], resultados['desviacion']
    x = np.linspace(retornos_limpios.min(), retornos_limpios.max(), 100)
    
    # 1. Histograma con curva normal superpuesta
    fig1, ax1 = plt.subplots(figsize=(10, 6))
    n, bins, patches = ax1.hist(retornos_limpios, bins=50, density=True, 
                                  alpha=0.7, color='skyblue', edgecolor='black')
    ax1.plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, 
             label='Distribuci√≥n Normal')
    ax1.set_xlabel('Log Returns', fontsize=12)
    ax1.set_ylabel('Densidad', fontsize=12)
    ax1.set_title('Histograma vs Distribuci√≥n Normal', fontsize=14, fontweight='bold')
    ax1.legend(fontsize=10)
    ax1.grid(True, alpha=0.3)
    plt.tight_layout()
    archivo1 = os.path.join(carpeta_salida, '01_histograma_normal.png')
    plt.savefig(archivo1, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"‚úì Guardado: {archivo1}")
    
    # 2. Q-Q Plot (Quantile-Quantile)
    fig2, ax2 = plt.subplots(figsize=(10, 6))
    stats.probplot(retornos_limpios, dist="norm", plot=ax2)
    ax2.set_title('Q-Q Plot (Normal)', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    plt.tight_layout()
    archivo2 = os.path.join(carpeta_salida, '02_qq_plot.png')
    plt.savefig(archivo2, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"‚úì Guardado: {archivo2}")
    
    # 3. Distribuci√≥n de las colas (escala logar√≠tmica)
    fig3, ax3 = plt.subplots(figsize=(10, 6))
    ax3.hist(retornos_limpios, bins=50, density=True, alpha=0.7, 
             color='skyblue', edgecolor='black')
    ax3.plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, 
             label='Normal')
    ax3.set_yscale('log')
    ax3.set_xlabel('Log Returns', fontsize=12)
    ax3.set_ylabel('Densidad (escala log)', fontsize=12)
    ax3.set_title('Colas en Escala Logar√≠tmica', fontsize=14, fontweight='bold')
    ax3.legend(fontsize=10)
    ax3.grid(True, alpha=0.3)
    plt.tight_layout()
    archivo3 = os.path.join(carpeta_salida, '03_colas_escala_log.png')
    plt.savefig(archivo3, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"‚úì Guardado: {archivo3}")
    
    # 4. Box Plot
    fig4, ax4 = plt.subplots(figsize=(10, 6))
    ax4.boxplot(retornos_limpios, vert=True)
    ax4.set_ylabel('Log Returns', fontsize=12)
    ax4.set_title('Box Plot - Valores Extremos', fontsize=14, fontweight='bold')
    ax4.grid(True, alpha=0.3)
    plt.tight_layout()
    archivo4 = os.path.join(carpeta_salida, '04_box_plot.png')
    plt.savefig(archivo4, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"‚úì Guardado: {archivo4}")
    
    # 5. Serie temporal de retornos
    fig5, ax5 = plt.subplots(figsize=(12, 6))
    ax5.plot(retornos_limpios.values, linewidth=0.5, alpha=0.7, color='steelblue')
    ax5.axhline(y=mu, color='r', linestyle='--', label='Media', linewidth=2)
    ax5.axhline(y=mu + 3*sigma, color='orange', linestyle='--', label='¬±3œÉ', linewidth=2)
    ax5.axhline(y=mu - 3*sigma, color='orange', linestyle='--', linewidth=2)
    ax5.set_xlabel('Observaci√≥n', fontsize=12)
    ax5.set_ylabel('Log Returns', fontsize=12)
    ax5.set_title('Serie Temporal de Retornos', fontsize=14, fontweight='bold')
    ax5.legend(fontsize=10)
    ax5.grid(True, alpha=0.3)
    plt.tight_layout()
    archivo5 = os.path.join(carpeta_salida, '05_serie_temporal.png')
    plt.savefig(archivo5, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"‚úì Guardado: {archivo5}")
    
    # 6. Comparaci√≥n de percentiles
    fig6, ax6 = plt.subplots(figsize=(10, 6))
    percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]
    percentiles_observados = [np.percentile(retornos_limpios, p) for p in percentiles]
    percentiles_normal = [stats.norm.ppf(p/100, mu, sigma) for p in percentiles]
    
    ax6.plot(percentiles, percentiles_observados, 'o-', label='Observado', 
             linewidth=2, markersize=8, color='steelblue')
    ax6.plot(percentiles, percentiles_normal, 's--', label='Normal te√≥rico', 
             linewidth=2, markersize=8, color='red', alpha=0.7)
    ax6.set_xlabel('Percentil', fontsize=12)
    ax6.set_ylabel('Valor', fontsize=12)
    ax6.set_title('Comparaci√≥n de Percentiles', fontsize=14, fontweight='bold')
    ax6.legend(fontsize=10)
    ax6.grid(True, alpha=0.3)
    plt.tight_layout()
    archivo6 = os.path.join(carpeta_salida, '06_percentiles.png')
    plt.savefig(archivo6, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"‚úì Guardado: {archivo6}")
    
    print(f"\n‚úÖ Todos los gr√°ficos guardados en la carpeta: {carpeta_salida}")
    print(f"   Total de archivos: 6 im√°genes PNG")

def main():
    """
    Funci√≥n principal
    """
    # Solicitar nombre del archivo
    print("="*70)
    print("AN√ÅLISIS DE FAT TAILS EN DEL ORO (PRECIOS DIARIOS)")
    print("="*70)

    # Cambiar a archivo CSV
    archivo = "Gold_Spot_historical_data.csv"

    # Cargar datos
    df = cargar_datos(archivo)
    if df is None:
        return
    
    # Verificar que el DataFrame no est√© vac√≠o
    if len(df) == 0:
        print("\n‚ùå Error: El archivo no contiene datos")
        return

    # Mostrar informaci√≥n sobre las columnas
    print(f"\nüìä Informaci√≥n del DataFrame:")
    print(f"   Forma: {df.shape} (filas, columnas)")
    print(f"   Columnas: {list(df.columns)}")
    
    # Intentar identificar la columna de log returns o returns
    # Buscar variaciones comunes del nombre
    posibles_nombres_returns = [
        'returns', 'Returns', 'RETURNS',
        'log returns', 'Log Returns', 'LOG RETURNS', 
        'log_returns', 'LogReturns', 'log return',
        'Log Return', 'return', 'Return'
    ]
    
    columna_returns = None
    for nombre in posibles_nombres_returns:
        if nombre in df.columns:
            columna_returns = nombre
            print(f"\n‚úì Encontrada columna de retornos: '{columna_returns}'")
            break
    
    if columna_returns is None:
        print("\n‚ùå No se encuentra una columna de returns")
        print("Columnas disponibles:")
        for i, col in enumerate(df.columns, 1):
            print(f"   {i}. {col}")
        
        # Si no hay columna de returns pero hay precio, calcularla
        posibles_nombres_precio = ['price', 'Price', 'PRICE', 'gold price', 
                                   'Gold Price', 'Close', 'close']
        columna_precio = None
        for nombre in posibles_nombres_precio:
            if nombre in df.columns:
                columna_precio = nombre
                break
        
        if columna_precio is not None:
            print(f"\n‚úì Encontrada columna de precio: '{columna_precio}'")
            print("üìä Calculando log returns...")
            df['log_returns'] = np.log(df[columna_precio] / df[columna_precio].shift(1))
            columna_returns = 'log_returns'
            print(f"‚úì Log returns calculados: {df[columna_returns].notna().sum()} valores v√°lidos")
        else:
            print("\n‚ùå Tampoco se encuentra una columna de precios para calcular returns")
            print("\nPor favor, aseg√∫rate de que el archivo tenga una columna con:")
            print("  - Returns (con nombres como 'returns', 'Returns', etc.)")
            print("  - O una columna de precios (con nombres como 'price', 'Price', etc.)")
            return
    
    # Convertir la columna de returns a num√©rico (por si tiene formato de porcentaje como texto)
    # Primero, eliminar el s√≠mbolo % si existe y convertir
    if df[columna_returns].dtype == 'object':
        print(f"\nüìù Convirtiendo columna '{columna_returns}' de texto a num√©rico...")
        # Eliminar % y convertir a decimal
        df[columna_returns] = df[columna_returns].str.rstrip('%').astype('float') / 100.0
        print(f"‚úì Conversi√≥n completada")
    
    # Analizar fat tails
    print(f"\nüîç Analizando fat tails usando la columna: '{columna_returns}'")
    resultados, retornos_limpios = analizar_fat_tails(df[columna_returns])
    
    # Imprimir resultados
    imprimir_resultados(resultados)
    
    # Calcular exponentes de cola (Estimador de Hill)
    print("\nüî¨ Calculando exponentes de cola...")
    resultados_hill = analizar_exponentes_cola(retornos_limpios)
    
    # Crear visualizaciones
    print("\nüìà Generando visualizaciones...")
    crear_visualizaciones(retornos_limpios, resultados)
    
    print("\n‚úì An√°lisis completado exitosamente!")

if __name__ == "__main__":
    main()
